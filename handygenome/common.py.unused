"""
Reference genome version aliases

MGSCv37 == mm9
GRCm38 == mm10
GRCm39 == mm39
NCBI36 == hg18
GRCh37 == hg19
GRCh38 == hg38
"""


import sys
import os

import re
import time
import datetime
import tempfile
import collections
import json
import pprint
import shutil
import urllib.request
import urllib.parse
import urllib.error
import io
import contextlib
import inspect
import itertools
import functools
import gzip
import subprocess
import signal
import logging
import importlib
import operator
import ftplib

import psutil
import pysam
import pandas as pd
import pyranges as pr
import numpy as np
import Bio.Seq
import scipy.stats

import handygenome.deco as deco

#TOP_PACKAGE_NAME = __name__.split('.')[0]
#TOP_PACKAGE = importlib.import_module(TOP_PACKAGE_NAME)
#PROJECT_PATH = os.path.dirname(os.path.dirname(TOP_PACKAGE.__file__))
#PACKAGE_LOCATION = PROJECT_PATH
#DATA_DIR = os.path.join(PROJECT_PATH, 'data')
#UTILS_DIR = os.path.join(PROJECT_PATH, 'externals')
#R_DIR = os.path.join(PROJECT_PATH, 'R')

#DEFAULT_VCFVER = '4.3'

# re patterns
#RE_PATS = {
#    'int' : re.compile('-?[0-9]+'),
#    'float' : re.compile('(-?[0-9]+\.[0-9]+)|(-?[0-9]+(\.[0-9]+)?e-?[0-9]+)'),
#    'nucleobases' : re.compile('[ACGTNacgtn]+'),
#    'numbered_chromosome' : re.compile('(chr)?[0-9]+'),
#    'assembled_chromosome' : re.compile('(chr)?([0-9]+|X|Y)'),
#
#    'alt_bndstring_1' : re.compile('^(?P<t>[^\[\]]+)(?P<bracket1>\[|\])(?P<matechrom>[^:]+):(?P<matepos>[0-9]+)(?P<bracket2>\[|\])$'),
#    'alt_bndstring_2' : re.compile('^(?P<bracket1>\[|\])(?P<matechrom>[^:]+):(?P<matepos>[0-9]+)(?P<bracket2>\[|\])(?P<t>[^\[\]]+)$'),
#        # these bndstring patterns assume that "t" portion must not be blank
#}



# SV symbolic allele strings
#SV_ALTS = ('DEL', 'INS', 'DUP', 'INV', 'CNV', 'BND', 'TRA')
#CPGMET_ALT = 'CPGMET'

# executable paths
#BASH = '/usr/bin/bash'
#BWA = os.path.join(UTILS_DIR, 'bwa')
#BEDTOOLS = os.path.join(UTILS_DIR, 'bedtools')
#GATK = os.path.join(UTILS_DIR, 'gatk_wrapper.sh')

#PERL = '/home/users/pjh/scripts/conda_wrapper/perl'
#PYTHON = '/home/users/pjh/tools/miniconda/221104/miniconda3/envs/genome_v7/bin/python'

#VEP_V102 = '/home/users/pjh/scripts/conda_wrapper/vep_v102' # for mm10
#VEP_V104 = '/home/users/pjh/scripts/conda_wrapper/vep_v104'
#VEP_V105 = '/home/users/pjh/scripts/conda_wrapper/vep_v105'
#VEP = VEP_V105
#VEP_MM10 = VEP_V102

#CONDABIN_PATH = '/home/users/pjh/conda_bin'
#SAMTOOLS = os.path.join(CONDABIN_PATH, 'samtools')
#BCFTOOLS = os.path.join(CONDABIN_PATH, 'bcftools')
#TABIX = os.path.join(UTILS_DIR, 'tabix')
#BEDTOOLS = os.path.join(CONDABIN_PATH, 'bedtools')

# vep cache directory
#VEP_CACHE_DIR = '/home/users/pjh/.vep'

# vcf format constants
#BCFTOOLS_FORMAT_DICT = { 'v':'w', 'z':'wz', 'u':'wbu', 'b':'wb' }
#CYVCF2_FORMAT_DICT = BCFTOOLS_FORMAT_DICT
#PYSAM_FORMAT_DICT = { 'v':'wz0', 'z':'wz', 'u':'wb0', 'b':'wb' }
#PYSAM_MODE_DICT = PYSAM_FORMAT_DICT
#DEFAULT_MODE_BCFTOOLS = 'z'

# http function constants


# colors


###################################################


#class RefverDict(collections.UserDict):
#    standards_byspecies = {
#        'Mus_musculus': (
#            'MGSCv3', 
#            'MGSCv34', 
#            'MGSCv35', 
#            'MGSCv36', 
#            'MGSCv37', 
#            'GRCm38', 
#            'GRCm39',
#        ),
#        'Homo_sapiens': (
#            'NCBI33', 
#            'NCBI34', 
#            'NCBI35', 
#            'NCBI36', 
#            'GRCh37', 
#            'GRCh37_hs37d5', 
#            'GRCh38', 
#            'T2T-CHM13v2',
#        ),
#        'Musa_acuminata': (
#            'ASM31385v1',
#            'ASM31385v2',
#        ),
#    }
#    standards = tuple(itertools.chain.from_iterable(standards_byspecies.values()))
##    (
##        # mouse
##        'MGSCv3', 'MGSCv34', 'MGSCv35', 'MGSCv36', 'MGSCv37', 'GRCm38', 'GRCm39', 
##        # human
##        'NCBI33', 'NCBI34', 'NCBI35', 'NCBI36', 'GRCh37', 'GRCh37_hs37d5', 'GRCh38', 'T2T-CHM13v2',
##        # others
##        'banana',
##    )
#    aliases = {
#        'NCBI36': ('hg18', 'ncbi36'),
#        'GRCh37': ('hg19', 'grch37'),
#        'GRCh38': ('hg38', 'grch38'),
#
#        'MGSCv37': ('mm9',),
#        'GRCm38': ('mm10', 'grcm38'),
#        'GRCm39': ('mm39', 'grcm39'),
#
#        'ASM31385v2': ('banana',),
#    }
#    assert set(aliases.keys()).issubset(standards)
#    known_refvers = (
#        tuple(standards)
#        + tuple(itertools.chain.from_iterable(aliases.values()))
#    )
#
#    @classmethod
#    def standardize(cls, refver):
#        if refver in cls.standards:
#            return refver
#        else:
#            for standard, alias_list in cls.aliases.items():
#                if refver in alias_list:
#                    return standard
#            raise Exception(f'Input reference version string ({refver}) is unknown one.')
#
#    def __init__(self, *args, **kwargs):
#        super().__init__(*args, **kwargs)
#        if not set(self.keys()).issubset(self.__class__.standards):
#            raise Exception(
#                f'RefverDict construction keys must be restricted to: '
#                f'{self.__class__.standards}'
#            )
#
#    def __getitem__(self, key):
#        key = self.__class__.standardize(key)
#        try:
#            result = super().__getitem__(key)
#        except KeyError:
#            raise Exception(f'Input reference version is not available.')
#
#        return result
#
#    def __contains__(self, key):
#        key = self.__class__.standardize(key)
#        return super().__contains__(key)
#
#    def get_valid_keys(self):
#        result = list()
#        for key in self.keys():
#            result.append(key)
#            if key in self.__class__.aliases.keys():
#                result.extend(self.__class__.aliases[key])
#        return result


# chr1 lengths
#CHR1_LENGTHS = RefverDict({
#    'MGSCv37': 197_195_432,
#    'GRCm38': 195_471_971,
#    'GRCm39': 195_154_279,
#    'NCBI36': 247_249_719,
#    'GRCh37': 249_250_621,
#    'GRCh38': 248_956_422,
#    'ASM31385v2': 41_765_374,
#})
#CHR1_LENGTHS_REV = {val: key for key, val in CHR1_LENGTHS.items()}

# default fasta paths


#DEFAULT_FASTA_PATHS = RefverDict({
#    'NCBI36': '/home/users/pjh/References/reference_genome/NCBI36/ucsc/custom_files/hg18.fa',
#    'GRCh37': '/home/users/data/01_reference/human_g1k_v37/human_g1k_v37.fasta',
#    'GRCh37_hs37d5': '/home/users/sypark/02_Reference/15_pcawg/genome.fa',
#    'GRCh38': '/home/users/data/01_reference/human_g1k_v38/Homo_sapiens_assembly38.fasta',
#
#    'MGSCv37': '/home/users/pjh/References/reference_genome/mm9/ucsc/custom_files/mm9.fa',
#    'GRCm38': '/home/users/pjh/References/reference_genome/GRCm38/ucsc/custom_files/mm10.fa',
#    'GRCm39': '/home/users/pjh/References/reference_genome/GRCm39/ucsc/custom_files/mm39.fa',
#
#    #'banana': '/home/users/yeonjin/practice/banana/reference/Musa_acuminata_pahang_v4_cp.fasta',
#    })

#DEFAULT_FASTAS = RefverDict({refver: pysam.FastaFile(path) for refver, path in DEFAULT_FASTA_PATHS.items()})


#AVAILABLE_REFVERS = tuple(DEFAULT_FASTA_PATHS.keys())
#AVAILABLE_REFVERS_PLUSNONE = AVAILABLE_REFVERS + (None,)


####################################################


#class ChromDict(collections.OrderedDict):
#    @deco.get_deco_num_set_differently(
#        ('fasta_path', 'fasta', 'bam_path', 'bam', 
#         'vcfheader', 'bamheader', 'custom', 'refver'), 1)
#    def __init__(self, fasta_path=None, fasta=None, bam_path=None, bam=None, 
#                 vcfheader=None, bamheader=None, custom=None, refver=None):
#        """
#        Args:
#            fasta: pysam.FastaFile object
#            bam: pysam.AlignmentFile object
#            vcfheader: pysam.VariantHeader object
#            bamheader: pysam.AlignmentHeader object
#            custom: {'contigs': ['contig1', 'contig2', ...], 
#                     'lengths': [length1, length2, ...] }
#        """
#
#        # set self dict
#        if vcfheader is not None:
#            for contig in vcfheader.contigs.values():
#                self[contig.name] = contig.length
#        elif custom is not None:
#            for chrom, length in zip(custom['contigs'], custom['lengths']):
#                self[chrom] = length
#        else:
#            if fasta_path is not None:
#                wrapper = pysam.FastaFile(fasta_path)
#            elif fasta is not None:
#                wrapper = fasta
#            elif bam_path is not None:
#                wrapper = pysam.AlignmentFile(bam_path)
#            elif bam is not None:
#                wrapper = bam
#            elif bamheader is not None:
#                wrapper = bamheader
#            elif refver is not None:
#                wrapper = DEFAULT_FASTAS[refver]
#    
#            for chrom, length in zip(wrapper.references, wrapper.lengths):
#                self[chrom] = length
#    
#            if any((x is not None) for x in (fasta_path, bam_path)):
#                wrapper.close()
#
#        # set contigs, lengths
#        self.contigs = list(self.keys())
#        self.lengths = list(self.values())
#
#    def get_cumpos0(self, chrom, pos0):
#        chromidx = self.contigs.index(chrom)
#        if chromidx == 0:
#            return pos0
#        else:
#            return pos0 + sum(self.lengths[:chromidx])
#
#    @functools.cached_property
#    def is_chr_prefixed(self):
#        relevant_chroms = [
#            x for x in self.contigs 
#            if RE_PATS['assembled_chromosome'].fullmatch(x) is not None
#        ]
#        startswith_chr = [x.startswith('chr') for x in relevant_chroms]
#        if all(startswith_chr):
#            return True
#        elif not any(startswith_chr):
#            return False
#        else:
#            raise Exception(f'Chromosome names are inconsistent of whether prefixed with "chr"')
#
#    @functools.cached_property
#    def XY_names(self):
#        def helper(name, xy):
#            assert xy in ('X', 'Y')
#            if name in self.contigs:
#                return name
#            else:
#                raise Exception(f'No {xy} chromosome name detected')
#            
#        if self.is_chr_prefixed:
#            X = helper('chrX', 'X')
#            Y = helper('chrY', 'Y')
#        else:
#            X = helper('X', 'X')
#            Y = helper('Y', 'Y')
#
#        return X, Y
#
#    @functools.cached_property
#    def assembled_chroms(self):
#        return [x for x in self.contigs if RE_PATS['assembled_chromosome'].fullmatch(x) is not None]
#
#    def to_gr(self, assembled_only=True, as_gr=True):
#        result = pd.DataFrame({
#            'Chromosome': self.contigs,
#            'Start': 0,
#            'End': self.lengths,
#        })
#        if assembled_only:
#            selector = result['Chromosome'].apply(
#                lambda x: RE_PATS['assembled_chromosome'].fullmatch(x) is not None
#            )
#            result = result.loc[selector, :]
#
#        if as_gr:
#            return pr.PyRanges(result)
#        else:
#            return result
#
#    def to_interval_list(self):
#        intvlist = IntervalList()
#        for contig, length in zip(self.contigs, self.lengths):
#            interval = Interval(contig, start0=0, end0=length)
#            intvlist.append(interval)
#
#        return intvlist
#
#    def get_chrom_indexes(self, chroms):
#        if np.isscalar(chroms):
#            return self.contigs.index(chroms)
#        else:
#            where = np.where(
#                np.array(chroms)[:, np.newaxis] == np.array(self.contigs)
#            )
#            assert len(set(where[0])) == len(chroms), f'Unknown chromosome names are included.'
#            result = [
#                tuple(subiter)[0][1] for key, subiter in itertools.groupby(
#                    zip(where[0], where[1]), key=operator.itemgetter(0)
#                )
#            ]
#            return result
#
#    def get_chrompos_sortkey(self, chroms, start0s=None, end0s=None):
#        assert not ((start0s is None) and (end0s is not None))
#
#        chrom_indexes = self.get_chrom_indexes(chroms)
#        if start0s is None:
#            sortkey = np.lexsort([chrom_indexes])
#        else:
#            if end0s is None:
#                sortkey = np.lexsort([start0s, chrom_indexes])
#            else:
#                sortkey = np.lexsort([end0s, start0s, chrom_indexes])
#
#        return sortkey
#
#    def sort_chrompos(self, chroms, start0s=None, end0s=None):
#        assert not ((start0s is None) and (end0s is not None))
#
#        # arg handling
#        chroms = np.array(chroms)
#        if start0s is not None:
#            start0s = np.array(start0s)
#        if end0s is not None:
#            end0s = np.array(end0s)
#
#        # result
#        sortkey = self.get_chrompos_sortkey(chroms, start0s, end0s)
#        if start0s is None:
#            return chroms[sortkey]
#        else:
#            if end0s is None:
#                return chroms[sortkey], start0s[sortkey]
#            else:
#                return chroms[sortkey], start0s[sortkey], end0s[sortkey]


#DEFAULT_CHROMDICTS = RefverDict({
#    key: ChromDict(fasta=val) for key, val in DEFAULT_FASTAS.items()
#    if key != 'GRCh37_hs37d5'
#})


#class Interval:
#    """
#    Attributes:
#        chrom
#        start0
#        end0
#        start1
#        end1
#        range0
#        length
#    """
#
#    def __init__(
#        self, chrom, *, start1=None, end1=None, start0=None, end0=None, is_reverse=False,
#    ):
#        """Args:
#            'chrom' is mandatory.
#            ('start1' and 'end1') or ('start0' and 'end0') must 
#                be given (for coordinate setting).
#            'start0' and 'end0' are 0-based half-open system.
#            'start1' and 'end1' are 1-based closed system.
#        """
#
#        self.chrom = chrom
#        self.is_reverse = is_reverse
#
#        # start0, end0, start1, end1
#        if (start1 is not None) and (end1 is not None):
#            self.start0 = start1 - 1
#            self.end0 = end1
#        else:
#            self.start0 = start0
#            self.end0 = end0
#
#        self.start1 = self.start0 + 1
#        self.end1 = self.end0
#
#        # range
#        self.range0 = range(self.start0, self.end0)
#
#        # length
#        self.length = self.end0 - self.start0
#
#    def __repr__(self):
#        return (f'<Interval> {self.chrom}:{self.start1:,}-{self.end1:,} '
#                f'(1-based)')
#
#    def to_gr(self, **kwargs):
#        data = {
#            'Chromosome': [self.chrom],
#            'Start': [self.start0],
#            'End': [self.end0],
#        }
#        for key, val in kwargs.items():
#            data[key] = [val]
#        return pr.from_dict(data)
#
#    @classmethod
#    def from_gr(cls, gr):
#        assert len(gr) == 1
#        return cls(chrom=gr.Chromosome[0], start0=gr.Start[0], end0=gr.End[0])
#
#    def includes(self, other):
#        return (self.chrom == other.chrom and
#                self.start0 <= other.start0 and
#                self.end0 >= other.end0)
#
#
#class IntervalList(list):
#    def __init__(self, *args, **kwargs):
#        super().__init__(*args, **kwargs)
#        self._lengths_cumsum = None
#
#    # constructors #
#    @classmethod
#    def from_gr(cls, gr):
#        result = cls()
#        for chrom, start0, end0 in zip(gr.Chromosome, gr.Start, gr.End):
#            intv = Interval(chrom=chrom, start0=start0, end0=end0)
#            result.append(intv)
#        return result
#
#    @classmethod
#    def from_bed(cls, bedfile):
#        gr = pr.read_bed(bedfile)
#        return cls.from_gr(gr)
#
#    @classmethod
#    def from_chromdict(cls, chromdict):
#        result = cls()
#        for contig, length in chromdict.items():
#            result.append(Interval(chrom=contig, start0=0, end0=length))
#
#        return result
#
#    @classmethod
#    def from_vcfspec(cls, vcfspec):
#        return cls.from_gr(cls, vcfspec.to_gr())
#
#    @classmethod
#    def from_margin(cls, refver, chrom_left, start0_left, chrom_right, end0_right):
#        chromdict = DEFAULT_CHROMDICTS[refver]
#        cumpos0_left = chromdict.get_cumpos0(chrom_left, start0_left)
#        cumpos0_right = chromdict.get_cumpos0(chrom_right, end0_right)
#        if cumpos0_left >= cumpos0_right:
#            raise Exception(
#                f'"left position" comes later than "right_position"; '
#                f'chrom_left={chrom_left}, start0_left={start0_left}, '
#                f'chrom_right={chrom_right}, end0_right={end0_right}'
#            )
#
#        result = cls()
#        if chrom_left == chrom_right:
#            result.append(Interval(chrom=chrom_left, start0=start0_left, end0=end0_right))
#        else:
#            chrom_left_idx = chromdict.contigs.index(chrom_left)
#            chrom_right_idx = chromdict.contigs.index(chrom_right)
#            result.append(
#                Interval(chrom=chrom_left, start0=start0_left, end0=chromdict[chrom_left])
#            )
#            for chrom in chromdict.contigs[(chrom_left_idx + 1):chrom_right_idx]:
#                result.append(
#                    Interval(chrom=chrom, start0=0, end0=chromdict[chrom])
#                )
#            result.append(
#                Interval(chrom=chrom_right, start0=0, end0=end0_right)
#            )
#
#        return result
#
#    @classmethod
#    def get_depth_bins(cls, refver, width=100_000):
#        result = cls()
#        chromdict = ChromDict(refver=refver)
#        for contig, length in zip(chromdict.contigs, chromdict.lengths):
#            intvlist_contig = cls()
#            intvlist_contig.append(Interval(chrom=contig, start0=0, end0=length))
#            for item in intvlist_contig.split(width=width):
#                result.extend(item)
#        return result
#    ################
#
#    def write_bed(self, outfile_path):
#        with openfile(outfile_path, 'w') as outfile:
#            for intv in self:
#                outfile.write(f'{intv.chrom}\t{intv.start0}\t{intv.end0}\n')
#
#    def to_gr(self):
#        chroms = list()
#        starts = list()
#        ends = list()
#        for intv in self:
#            chroms.append(intv.chrom)
#            starts.append(intv.start0)
#            ends.append(intv.end0)
#        return pr.from_dict({'Chromosome': chroms, 'Start': starts, 'End': ends})
#
#    # properties
#    @functools.cached_property
#    def lengths_cumsum(self):
#        return list(itertools.accumulate(intv.length for intv in self))
#    @property
#    def length(self):
#        return sum(intv.length for intv in self)
#
#    # inclusion check
#    def includes_vr(self, vr):
#        vr_intv = Interval(chrom=vr.contig, start1=vr.pos, end1=vr.pos)
#        return any(intv.includes(vr_intv) for intv in self)
#
#    # calculations
#    def sort_intervals(self, chromdict):
#        def sortkey(intv):
#            return coord_sortkey(intv.chrom, intv.start1, chromdict)
#        self.sort(key=sortkey)
#
#    def isec(self, other):
#        self_gr = self.to_gr()
#        other_gr = other.to_gr()
#        isec_gr = self_gr.set_intersect(other_gr)
#
#        return self.__class__.from_gr(isec_gr)
#
#    def subtract(self, other):
#        self_gr = self.to_gr()
#        other_gr = other.to_gr()
#        subtract_gr = self_gr.subtract(other_gr)
#
#        return self.__class__.from_gr(subtract_gr)
#
#    def union(self, other):
#        self_gr = self.to_gr()
#        other_gr = other.to_gr()
#        union_gr = self_gr.set_union(other_gr)
#
#        return self.__class__.from_gr(union_gr)
#
#    def merge(self):
#        return self.__class__.from_gr(self.to_gr().merge())
#
#    @deco.get_deco_num_set(('b', 'l', 'r'), 1)
#    def slop(self, chromdict, b=None, l=None, r=None):
#        def start_handler(start0, width):
#            new_start0 = max(0, start0 - width)
#            return new_start0
#
#        def end_handler(end0, width, chrom, chromdict):
#            new_end0 = min(chromdict[chrom], end0 + width)
#            return new_end0
#
#        result = self.__class__()
#        for intv in self:
#            if b is not None:
#                new_start0 = start_handler(intv.start0, b)
#                new_end0 = end_handler(intv.end0, b, intv.chrom, chromdict)
#            elif l is not None:
#                new_start0 = start_handler(intv.start0, l)
#                new_end0 = intv.end0
#            elif r is not None:
#                new_start0 = new_start0
#                new_end0 = end_handler(intv.end0, b, intv.chrom, chromdict)
#
#            new_intv = Interval(chrom=intv.chrom, start0=new_start0, end0=new_end0)
#            result.append(new_intv)
#
#        return result
#
#    @deco.get_deco_num_set(('num', 'width'), 1)
#    def split(self, *, num=None, width=None):
#        #self.sort_intervals(chromdict)
#
#        # get result_lengths_cumsum
#        total_length = self.lengths_cumsum[-1]
#        if num is not None:
#            result_lengths_cumsum = list(itertools.accumulate(
#                get_interval_lengths_num(total_length, num)))
#        elif width is not None:
#            result_lengths_cumsum = list(itertools.accumulate(
#                get_interval_lengths_width(total_length, width)))
#
#        # prepare result values
#        result = list()
#        for idx in range(len(result_lengths_cumsum)):
#            # get start0 and end0 in the single merged coordinate system
#            merged_start0 = (0 
#                             if idx == 0 else
#                             result_lengths_cumsum[idx - 1])
#            merged_end0 = result_lengths_cumsum[idx]
#            # modify merged coordinates into interval-specific ones
#            (chrom_start, 
#             pos0_start, 
#             self_idx_start) = self._modify_coord(merged_start0, is_end=False)
#            (chrom_end, 
#             pos0_end, 
#             self_idx_end) = self._modify_coord(merged_end0, is_end=True)
#            # create an IntervalList corresponding to a split unit
#            intvlist = IntervalList()
#            if self_idx_start == self_idx_end:
#                intv = Interval(chrom_start, start0=pos0_start, end0=pos0_end)
#                intvlist.append(intv)
#            else:
#                intv_first = Interval(chrom_start, 
#                                      start0=pos0_start, 
#                                      end0=self[self_idx_start].end0)
#                intvlist.append(intv_first)
#
#                for self_idx in range(self_idx_start + 1, self_idx_end):
#                    intvlist.append(self[self_idx])
#
#                intv_last = Interval(chrom_end, 
#                                     start0=self[self_idx_end].start0, 
#                                     end0=pos0_end)
#                intvlist.append(intv_last)
#
#            result.append(intvlist)
#
#        return result
#
#    def _modify_coord(self, merged_pos0, is_end=False):
#        def get_interval_values(merged_pos0, idx, self):
#            chrom = self[idx].chrom
#
#            if idx == 0:
#                shift_within_interval = merged_pos0
#            else:
#                shift_within_interval = (merged_pos0 
#                                         - self.lengths_cumsum[idx - 1])
#            new_pos0 = self[idx].start0 + shift_within_interval
#
#            return chrom, new_pos0
#
#        def handle_current_interval(merged_pos0, idx, length_previous, 
#                                    length_current, is_end):
#            if merged_pos0 > length_previous and merged_pos0 <= length_current:
#                if merged_pos0 == length_current:
#                    if is_end:
#                        chrom, new_pos0 = get_interval_values(
#                            merged_pos0, idx, self)
#                    else:
#                        chrom, new_pos0 = get_interval_values(
#                            merged_pos0, idx + 1, self)
#                elif merged_pos0 < length_current:
#                    chrom, new_pos0 = get_interval_values(merged_pos0, idx, 
#                                                          self)
#
#                to_break = True
#            else:
#                chrom = None
#                new_pos0 = None
#                to_break = False
#
#            return chrom, new_pos0, to_break
#
#        # sanity check
#        assert merged_pos0 >= 0, f'"merged_pos0" must be non-negative.'
#        assert not ((not is_end) and merged_pos0 >= self.lengths_cumsum[-1]), (
#            f'If ""is_end" is False, "merged_pos0" must be less than '
#            f'the total IntervalList length.')
#        assert not (is_end and merged_pos0 > self.lengths_cumsum[-1]), (
#            f'If ""is_end" is True, "merged_pos0" must be less than or '
#            f'equal to the total IntervalList length.')
#
#        if merged_pos0 == 0:
#            chrom = self[0].chrom
#            new_pos0 = self[0].start0
#            self_idx = 0
#        else:
#            for idx in range(len(self.lengths_cumsum)):
#                length_current = self.lengths_cumsum[idx]
#                length_previous = (0 
#                                   if idx == 0 else
#                                   self.lengths_cumsum[idx - 1])
#                (chrom, new_pos0, to_break) = handle_current_interval(
#                    merged_pos0, idx, length_previous, length_current, is_end)
#                self_idx = idx
#
#                if to_break:
#                    break
#
#        return chrom, new_pos0, self_idx




###################################################

## logger
#def make_funclogger(level, name):
#    level = getattr(logging, level.upper())
#    logger = logging.getLogger(name)
#    logger.setLevel(level)
#    logger.propagate = False
#    
#    formatter = logging.Formatter(
#        fmt='[%(asctime)s %(levelname)s] %(module)s.%(funcName): %(message)s', 
#        datefmt='%Z %Y-%m-%d %H:%M:%S',
#    )
#
#    sh = logging.StreamHandler()
#    sh.setLevel(level)
#    sh.setFormatter(formatter)
#    logger.addHandler(sh)
#
#    return logger
#
#
#FUNCLOGGER_DEBUG = make_funclogger(level='debug', name='FUNCLOGGER_DEBUG')
#FUNCLOGGER_INFO = make_funclogger(level='info', name='FUNCLOGGER_INFO')





###################################################



###################################################


#def rm_newline(line):
#    return re.sub('(\r)?\n$', '', line)
#
#
#def rm_newline_byte(byteline):
#    return re.sub(b'(\r)?\n$', b'', byteline)
#
#
#def get_linesp(line, sep='\t'):
#    return rm_newline(line).split(sep)
#
#
#def get_linesp_byte(byteline, sep=b'\t'):
#    return rm_newline_byte(byteline).split(sep)



#def get_indelseq(ref, alt):
#    mttype = get_mttype(ref, alt)
#    if mttype == 'ins':
#        indelseq = alt[1:]
#    elif mttype == 'del':
#        indelseq = ref[1:]
#    else:
#        indelseq = None
#    
#    return indelseq


###################################################

#def listdir(path):
#    return sorted(os.path.join(path, x) for x in os.listdir(path))
#
#
#def get_padded_indices(n):
#    """Begins with 0"""
#
#    width = len(str(n-1))
#    result = [str(idx).zfill(width) for idx in range(n)]
#
#    return result


###################################################


#def printwidth_get_width_list(df):
#    '''
#    df: [
#    [line1_field1, line1_field2, ... ],
#    [line2_field1, line2_field2, ... ],
#    ...,
#    ]
#    '''
#    width_list = list()
#    for i in range(len(df[0])):
#        width_list.append(list())
#
#    for line in df:
#        for idx, field in enumerate(line):
#            width_list[idx].append(len(field))
#
#    for idx, e in enumerate(width_list):
#        width_list[idx] = max(e)
#
#    return width_list
#
#
#def printwidth_print_line(line, width_list, margin, target):
#    printresult = ''
#    for idx, e in enumerate(line):
#        printresult += f'{e:>{width_list[idx] + margin}s}'
#    if target == 'out':
#        print(printresult, flush = True)
#    elif target == 'err':
#        print(printresult, flush = True, file = sys.stderr)
#
#
#def printwidth(df, margin = 2, target = 'out'):
#    for line in df:
#        for idx, e in enumerate(line):
#            line[idx] = str(e)
#
#    width_list = printwidth_get_width_list(df)
#    for line in df:
#        printwidth_print_line(line, width_list, margin, target)


###################################################

#@deco.get_deco_num_set(('chromdict', 'vcfheader', 'bamheader'), 1)
#def infer_refver(chromdict=None, vcfheader=None, bamheader=None):
#    if chromdict is not None:
#        return infer_refver_chromdict(chromdict)
#    elif vcfheader is not None:
#        return infer_refver_vcfheader(vcfheader)
#    elif bamheader is not None:
#        return infer_refver_bamheader(bamheader)
#
#
#def infer_refver_chromdict(chromdict):
#    return infer_refver_base(chromdict.contigs, chromdict.lengths)
#
#
#def infer_refver_vcfheader(vcfheader):
#    contigs = list()
#    lengths = list()
#    for contig in vcfheader.contigs.values():
#        contigs.append(contig.name)
#        lengths.append(contig.length)
#    return infer_refver_base(contigs, lengths)
#
#
#def infer_refver_vr(vr):
#    return infer_refver_vcfheader(vr.header)
#
#
#def infer_refver_fasta(fasta):
#    return infer_refver_pysamwrapper(fasta)
#
#
#def infer_refver_bamheader(bamheader):
#    return infer_refver_pysamwrapper(bamheader)
#
#
#def infer_refver_pysamwrapper(wrapper):
#    return infer_refver_base(wrapper.references, wrapper.lengths)
#
#
#def infer_refver_base(contigs, lengths):
#    chr1_names_candidates = {'1', 'chr1', 'chr01'}
#    intersection = chr1_names_candidates.intersection(contigs)
#    if len(intersection) == 0:
#        raise Exception(f'There is no chromosome name which looks like "chr1"')
#    elif len(intersection) > 1:
#        raise Exception(f'There is more than one  chromosome names which looks like "chr1"')
#    chr1_name = intersection.pop()
#    chr1_length = lengths[contigs.index(chr1_name)]
#    
#    if chr1_length in CHR1_LENGTHS_REV:
#        refver = CHR1_LENGTHS_REV[chr1_length]
#    else:
#        raise Exception(f'Cannot infer refver: unknown chr1 length')
#    
#    return refver


###################################################

## network functionalities
#
#def retry_or_raise(n_try, retry_count, exc, retry_interval):
#    if n_try > retry_count:
#        print(exc.read().decode('utf-8'))
#        raise Exception(f'Exceeded maximum retry count({retry_count}).') from exc
#    else:
#        if isinstance(exc, TimeoutError):
#            print_timestamp(f'Retrying due to TimeoutError (Exception: {exc}); n_try={n_try}')
#        else:
#            print_timestamp(f'Retrying; n_try={n_try}')
#        time.sleep(retry_interval)
#
#
## ftp
#
#def ftp_login(url, retry_count=10, retry_interval=1, timeout=5):
#    n_try = 0
#    while True:
#        n_try += 1
#        try:
#            with contextlib.redirect_stdout('/dev/null'):
#                ftp = ftplib.FTP(url, timeout=timeout)
#                ftp.login()
#        except TimeoutError as exc:
#            retry_or_raise(n_try, retry_count, exc, retry_interval)
#            continue
#        except OSError as exc:
#            if (str(exc) == '[Errno 101] Network is unreachable'):
#                retry_or_raise(n_try, retry_count, exc, retry_interval)
#                continue
#            else:
#                raise
#        else:
#            break
#
#    return ftp
#
#
#def trim_path(path):
#    path = re.sub('/+$', '', path)
#    path = re.sub('/{2,}', '/', path)
#    return path
#
#
#def join_ftp_paths(*args):
#    return trim_path('/'.join(args))
#
#
#def ftp_listdir(ftp, path):
#    path = trim_path(path)
#    fname_list = list()
#    ftp.cwd(path)
#    ftp.retrlines('NLST', callback=(lambda x: fname_list.append(path + '/' + x)))
#    return fname_list
#
#
## http
#
#def http_run_urlopen(url_or_req, retry_count=10, retry_interval=1, urlopen_timeout=5):
#    url_string = (
#        url_or_req
#        if isinstance(url_or_req, str) else
#        url_or_req.full_url
#    )
#    print_timestamp(f'Trying to open url {repr(url_string)}')
#
#    n_try = 0
#    while True:
#        n_try += 1
#        try:
#            response = urllib.request.urlopen(url_or_req, timeout=urlopen_timeout)
#        except urllib.error.URLError as exc:
#            if isinstance(exc, urllib.error.HTTPError):
#                if exc.code == 500:  # internal server error
#                    retry_or_raise(n_try, retry_count, exc, retry_interval)
#                    continue
#                else:
#                    print(exc.read().decode('utf-8'))
#                    raise
#            else: 
#                if str(exc) == '<urlopen error [Errno 101] Network is unreachable>':
#                    retry_or_raise(n_try, retry_count, exc, retry_interval)
#                    continue
#                else:
#                    print(exc.read().decode('utf-8'))
#                    raise
#        except TimeoutError as exc:
#            retry_or_raise(n_try, retry_count, exc, retry_interval)
#            continue
#        else:
#            break
#
#    print_timestamp(f'Succeeded to open url {repr(url_string)}')
#
#    return response
#
#
#def http_get(url, params=None, headers=None, text=False, retry_count=10, retry_interval=1):
#    # set params
#    if params is not None:
#        url = url + '?' + urllib.parse.urlencode(params)
#    if headers is None:
#        if text:
#            headers = {'Accept': 'text/plain'}
#        else:
#            headers = {'Accept': 'application/json'}
#    # main
#    req = urllib.request.Request(url, headers=headers, method='GET')
#    return http_send_request(req, text, retry_count, retry_interval)
#
#
#def http_post(url, data, params=None, headers=None, text=False, retry_count=10, retry_interval=1):
#    # set params
#    data = json.dumps(data).encode('ascii')
#    if params is not None:
#        url = url + '?' + urllib.parse.urlencode(params)
#    if headers is None:
#        if text:
#            headers = {'Accept': 'text/plain'}
#        else:
#            headers = {'Accept': 'application/json'}
#    # main
#    req = urllib.request.Request(url, data=data, headers=headers, method='POST')
#    return http_send_request(req, text, retry_count, retry_interval)
#
#
#def http_send_request(req, text, retry_count=10, retry_interval=1, urlopen_timeout=5):
#    with http_run_urlopen(
#        req, 
#        retry_count=retry_count, 
#        retry_interval=retry_interval, 
#        urlopen_timeout=urlopen_timeout,
#    ) as response:
#        if text:
#            result = response.read().decode('utf-8')
#        else:
#            result = json.loads(response.read())
#
#    return result
#
#
#def download(url, path, retry_count=10, retry_interval=1, urlopen_timeout=5):
#    while True:
#        try:
#            with http_run_urlopen(
#                url, 
#                retry_count=retry_count, 
#                retry_interval=retry_interval, 
#                urlopen_timeout=urlopen_timeout,
#            ) as response:
#                with open(path, 'wb') as outfile:
#                    shutil.copyfileobj(response, outfile)
#        except TimeoutError as exc:
#            print_timestamp(f'Retrying due to TimeoutError (Exception: {exc})')
#            continue
#        else:
#            break
#
#
#def download_wget(url, path):
#    subprocess.run(
#        ['wget', '-O', path, url],
#    )


######################################################


#def unzip(src, dest, rm_src=False):
#    with gzip.open(src, 'rb') as infile:
#        with open(dest, 'wb') as outfile:
#            shutil.copyfileobj(infile, outfile)      
#    if rm_src:
#        os.remove(src)
#
#
#@deco.get_deco_arg_choices({'mode': ('r', 'w', 'a')})
#def openfile(fname, mode='r'):
#    mode = mode + 't'
#
#    if fname.endswith('.gz'):
#        return gzip.open(fname, mode)
#    else:
#        return open(fname, mode)

###################################################

